{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jB6auQk-pe7J"
      },
      "source": [
        "<table>\n",
        "    <tr>\n",
        "      <td>Introducción a\n",
        "      </td>\n",
        "      <td>\n",
        "      <img src=\"https://media.licdn.com/dms/image/D5612AQF7GSp3l4pztQ/article-cover_image-shrink_720_1280/0/1686548640655?e=1715817600&v=beta&t=WQzv1EMkEEwZ0QZ0PF1anRKIHCl5BBH_YPZHdDQsWPM\"  width=150/>\n",
        "      </td>\n",
        "     </tr>\n",
        "</table>\n",
        "\n",
        "## Regresión lineal\n",
        "\n",
        "### Índice\n",
        "[Obtención del modelo](#modelo)<br>\n",
        "[Afinando el error](#error)<br>\n",
        "[Intervalo de confianza](#intervalo)<br>\n",
        "[Mejorando el modelo](#mejorando)<br>\n",
        "[Lasso y Ridge](#lasso)<br>\n",
        "[Regresión Series Temporales](#series)<br>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TLr3aKTDpkF4"
      },
      "source": [
        "<a name=\"modelo\"></a>\n",
        "## Obtención del modelo\n",
        "\n",
        "Empezamos cargando un fichero con las notas de las pruebas PISA. Recordamos la importancia del preprocesado, pero es aquí nos dan ya los datos preparados para que nos centremos en la regresión"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5wZOKxF0sUs2"
      },
      "outputs": [],
      "source": [
        "# Carga del fichero\n",
        "import pandas as pd\n",
        "url = \"https://raw.githubusercontent.com/RafaelCaballero/tdm/master/datos/pisaDataClean.csv\"\n",
        "df = pd.read_csv(url)\n",
        "df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Iz0bK6B48HGS"
      },
      "source": [
        "1.- Dividir las columnas en X e y en train y test. Nuestro objetivo será deducir la columna MAT desde SCI y REA"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xe1EtWSB5nfT"
      },
      "outputs": [],
      "source": [
        "\n",
        "XColumns = [\"SCI\", \"REA\"]\n",
        "yColumn = \"MAT\"\n",
        "X = df[XColumns]\n",
        "y = df[yColumn]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cVN7koqZnaO1"
      },
      "outputs": [],
      "source": [
        "X"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o5-4dCJHnaO1"
      },
      "outputs": [],
      "source": [
        "y"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tpFIcVPUnaO2"
      },
      "source": [
        "2.- Dividir las columnas en X e y en train y test. Nuestro objetivo será deducir la columna MAT desde SCI y REA"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2QQVXRmRnaO2"
      },
      "outputs": [],
      "source": [
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "test = 0.4\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size= test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vppjIMlMnaO2"
      },
      "outputs": [],
      "source": [
        "X_train"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jxLb1qAb9QxC"
      },
      "source": [
        "3.- Declarar el método y  entrenar con el conjunto train, obteniendo un *modelo*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aMyU4DUguOIy"
      },
      "outputs": [],
      "source": [
        "from sklearn.linear_model import LinearRegression\n",
        "metodo = LinearRegression()\n",
        "modelo = metodo.fit(X_train,y_train)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7p1BLXXbnaO2"
      },
      "source": [
        "El modelo representa simplemente la recta que mejor ajusta las (X,y) dadas:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LHR9IDl00uwK"
      },
      "outputs": [],
      "source": [
        "modelo.intercept_, modelo.coef_"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ICwOowl9naO3"
      },
      "source": [
        "Es decir, dada una nota en ciencia `sci` y lectura `rea`, se puede obtener la nota de matemáticas `mat` de la siguiente forma:\n",
        "\n",
        "mat = -23.91  + 0.87*sci + 0.16*rea    (ojo, estos números irán variando de ejecucióne en ejecución)\n",
        "\n",
        "Aunque veremos que estas predicciones las vamos a hacer automáticamente, podemos escribir por nuestra cuentra una función que las haga:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UAfY_9D4naO3"
      },
      "outputs": [],
      "source": [
        "def y_predict(X,modelo):\n",
        "    s = modelo.intercept_\n",
        "    for i,x in enumerate(X):\n",
        "        s += x*modelo.coef_[i]\n",
        "    return s\n",
        "\n",
        "y_predict([400,450],modelo)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HM8PDlphnaO3"
      },
      "source": [
        "Vamos a representar gráficamente los datos de entrenamiento y la recta modelo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": true,
        "id": "AFxWxhY9naO3"
      },
      "outputs": [],
      "source": [
        "from mpl_toolkits.mplot3d.axes3d import Axes3D\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib\n",
        "\n",
        "fig = plt.figure(figsize=(14,6))\n",
        "\n",
        "# projection='3d' indica que este subplot es en 3d\n",
        "ax = fig.add_subplot(1, 2, 1, projection='3d')\n",
        "x = X_train[\"SCI\"]\n",
        "y = X_train[\"REA\"]\n",
        "z = y_train\n",
        "ax.scatter3D( x, y, z)\n",
        "\n",
        "y_1 = y_predict([300,300],modelo)\n",
        "y_2 = y_predict([600,600],modelo)\n",
        "ax.plot3D([300,600],[300,600],[y_1,y_2],color=\"green\")\n",
        "ax.set_zlabel(r\"MAT\", fontsize=10, color=\"blue\")\n",
        "ax.set_xlabel(r\"SCI\", fontsize=10, color=\"blue\")\n",
        "ax.set_ylabel(r\"REA\", fontsize=10, color=\"blue\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "35PblQDe-BGD"
      },
      "source": [
        "4.- Ahora predecimos con el test y mostramos el error"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7XTbywcc-Adz"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import r2_score,mean_squared_error,mean_absolute_error\n",
        "import math\n",
        "y_pred = modelo.predict(X_test)\n",
        "r2 = r2_score(y_test,y_pred)\n",
        "rmse = math.sqrt(mean_squared_error(y_test,y_pred))\n",
        "mae = mean_absolute_error(y_test,y_pred)\n",
        "print(f\"r^2: {round(r2,3)} RMSE: {round(rmse,3)}, MAE:{round(mae,3)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cfPf0WmdnaO4"
      },
      "source": [
        "Y completamos la figura mostrando los puntos de entrenamiento, de test y la recta"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6bfrGeVwvdaM",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "fig = plt.figure(figsize=(14,6))\n",
        "\n",
        "# projection='3d' indica que este subplot es en 3d\n",
        "ax = fig.add_subplot(1, 2, 1, projection='3d')\n",
        "x = X_train[\"SCI\"]\n",
        "y = X_train[\"REA\"]\n",
        "z = y_train\n",
        "ax.scatter3D( x, y, z,label=\"train\")\n",
        "\n",
        "y_1 = y_predict([300,300],modelo)\n",
        "y_2 = y_predict([600,600],modelo)\n",
        "ax.plot3D([300,600],[300,600],[y_1,y_2],color=\"green\")\n",
        "ax.set_zlabel(r\"MAT\", fontsize=10, color=\"blue\")\n",
        "ax.set_xlabel(r\"SCI\", fontsize=10, color=\"blue\")\n",
        "ax.set_ylabel(r\"REA\", fontsize=10, color=\"blue\")\n",
        "\n",
        "\n",
        "##### Esto es lo nuevo\n",
        "x = X_test[\"SCI\"]\n",
        "y = X_test[\"REA\"]\n",
        "z = y_test\n",
        "ax.scatter3D( x, y, z,label=\"test\")\n",
        "plt.legend()\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nhmFxRkFCQxj"
      },
      "source": [
        "**Ejercicio 1** Repetir desde el paso 1, cambiando tan solo el tamaño del test a 0.95 ¿qué sucede con el error?\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oOs7QMTRnaO4"
      },
      "source": [
        "Este es un ejemplo de overfitting: cuando por alguna razón (en este caso por falta de datos de entrenamiento), el modelo generado se comporta mucho mejor sobre el entrenamiento que sobre el test. Repitamos todo el proceso:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Xann7gvnnaO4"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HDBV6V0CnaO4"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kE016sLhnaO4"
      },
      "source": [
        "<a name=\"error\"></a>\n",
        "\n",
        "\n",
        "## Afinando el error"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KAQsaIIvnaO4"
      },
      "source": [
        "**Ejercicio 2** Ejecutar varias veces el código anterior, se verá que se obtiene resultados diferentes ¿en qué punto del código se produce esta variación?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hZTz5TqRnaO5"
      },
      "source": [
        "De hecho, si se quieren obtener resultados con una cierta verosimilitud tendremos que repetir el experimento (pasos 2,3,4) varias veces. Vamos a instalar el paquete progress bar para ver cómo progresan los experimentos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OHSkUrm1naO5"
      },
      "outputs": [],
      "source": [
        "# Carga del fichero\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import r2_score,mean_squared_error,mean_absolute_error\n",
        "import math\n",
        "\n",
        "from tqdm import tqdm\n",
        "\n",
        "url = \"https://raw.githubusercontent.com/RafaelCaballero/tdm/master/datos/pisaDataClean.csv\"\n",
        "df = pd.read_csv(url)\n",
        "\n",
        "# 1\n",
        "XColumns = [\"SCI\", \"REA\"]\n",
        "yColumn = \"MAT\"\n",
        "X = df[XColumns]\n",
        "y = df[yColumn]\n",
        "\n",
        "veces = 500\n",
        "\n",
        "\n",
        "resultados = []\n",
        "for v in tqdm(range(veces)):\n",
        "    # 2\n",
        "    test = 0.4\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size= test)\n",
        "\n",
        "    # 3\n",
        "    metodo = LinearRegression()\n",
        "    modelo = metodo.fit(X_train,y_train)\n",
        "\n",
        "    # 4\n",
        "    y_pred = modelo.predict(X_test)\n",
        "    r2 = r2_score(y_test,y_pred)\n",
        "    rmse = math.sqrt(mean_squared_error(y_test,y_pred))\n",
        "    mae = mean_absolute_error(y_test,y_pred)\n",
        "    bias = (y_test - y_pred).mean()\n",
        "    resultados.append([round(r2,3),round(rmse,3),round(mae,3),round(bias,3)])\n",
        "    #print(f\"r^2: {round(r2,3)} RMSE: {round(rmse,3)}, MAE:{round(mae,3)}\")\n",
        "\n",
        "df_errores = pd.DataFrame(resultados,columns=[\"r^2\",\"RMSE\",\"MAE\",\"BIAS\"])\n",
        "df_errores"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KB1JIqvDnaO5"
      },
      "outputs": [],
      "source": [
        "df_errores.describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vEoCN20bnaO5"
      },
      "outputs": [],
      "source": [
        "df_errores.describe().loc[\"mean\"]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DKqBE7d2naO6"
      },
      "source": [
        "Es fácil hacer una función que haga el trabajo de los experimentos. Podemos usarla para evaluar la regresión con otros datos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5e7hhZWPnaO6"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import r2_score,mean_squared_error,mean_absolute_error\n",
        "import math\n",
        "from tqdm import tqdm\n",
        "\n",
        "def evalua_regresion(df,XColumns,yColumn,veces=500):\n",
        "    # 1\n",
        "    X = df[XColumns]\n",
        "    y = df[yColumn]\n",
        "\n",
        "\n",
        "\n",
        "    resultados = []\n",
        "    for v in tqdm(range(veces)):\n",
        "        # 2\n",
        "        test = 0.4\n",
        "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size= test)\n",
        "\n",
        "        # 3\n",
        "        metodo = LinearRegression()\n",
        "        modelo = metodo.fit(X_train,y_train)\n",
        "\n",
        "        # 4\n",
        "        y_pred = modelo.predict(X_test)\n",
        "        r2 = r2_score(y_test,y_pred)\n",
        "        rmse = math.sqrt(mean_squared_error(y_test,y_pred))\n",
        "        mae = mean_absolute_error(y_test,y_pred)\n",
        "        bias = (y_test - y_pred).mean()\n",
        "        resultados.append([round(r2,3),round(rmse,3),round(mae,3),round(bias,3)])\n",
        "        #print(f\"r^2: {round(r2,3)} RMSE: {round(rmse,3)}, MAE:{round(mae,3)}\")\n",
        "\n",
        "    df_errores = pd.DataFrame(resultados,columns=[\"r^2\",\"RMSE\",\"MAE\",\"BIAS\"])\n",
        "    return df_errores.describe().loc[\"mean\"]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dfgM0pNynaO6"
      },
      "outputs": [],
      "source": [
        "url = \"https://raw.githubusercontent.com/RafaelCaballero/tdm/master/datos/pisaDataClean.csv\"\n",
        "df = pd.read_csv(url)\n",
        "\n",
        "# 1\n",
        "XColumns = [\"SCI\", \"REA\"]\n",
        "yColumn = \"MAT\"\n",
        "print(evalua_regresion(df,XColumns,yColumn))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CDpzsD0EnaO6"
      },
      "source": [
        "**Ejercicio 3**\n",
        "\n",
        "- Si se en lugar de predecir \"MAT\" desde \"SCI\" y \"REA\" tuviéramos que predecir \"SCI\" desde las otras dos o \"REA\" desde las otras dos cual daría mejores resultados\n",
        "- Si solo queremos utilizar un atributo, ya sea \"SCI\" o \"REA\" para predecir \"MAT\" ¿cuál usarías?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UyTcldsJnaO7"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lMsJUf0InaO7"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-uZe8uBcnaO7"
      },
      "source": [
        "<a name=\"intervalo\"></a>\n",
        "## Intervalos de confianza"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WKwk9uCDnaO7"
      },
      "source": [
        "Si ahora ejecutamos varias veces el código veremos que los resultados son bastante estables. Aun así persiste una duda...cuando hagamos una predicción ¿podemos estimar lo lejos que está del valor real?\n",
        "\n",
        "Vamos a poder hacerlo con un par de condiciones:\n",
        "\n",
        "1.- Que el bias sea muy próximo a 0\n",
        "\n",
        "2.- Que el RMSE sea una normal\n",
        "\n",
        "La condición 1 la tenemos; hay que tener en cuenta que un valor de alrededor de -0.1...0.1 en"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BF3n_hODnaO7"
      },
      "outputs": [],
      "source": [
        "df.MAT.mean()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xOL2XVXfnaO7"
      },
      "source": [
        "es muy pequeño. En cuanto al RMSE por simplificar nos conformamos con \"ver\" el histograma"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TM2b_XZ3naO7"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "#fig, ax = plt.subplots(figsize=(5, 5))\n",
        "df_errores.RMSE.hist(bins=15)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S8xOVkqEnaO8"
      },
      "source": [
        "Asumiendo que esto es una normal, podemos decir que, con un 95% de probabilidades, para cualquier predicción p el valor real estará en el intervalo\n",
        "\n",
        "[p -2RMSE, p+2RMSE]\n",
        "\n",
        "Este intervalo de confianza se mantiene siempre y cuando estemos (aprox.) dentro del rango de valores usados en el entrenamiento"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5BymJwjjnaO8"
      },
      "outputs": [],
      "source": [
        "X_train.describe()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "od4JZJQ6naO8"
      },
      "source": [
        "**Ejemplo**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aWRHMvLgnaO8"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from sklearn.linear_model import LinearRegression\n",
        "\n",
        "url = \"https://raw.githubusercontent.com/RafaelCaballero/tdm/master/datos/pisaDataClean.csv\"\n",
        "df = pd.read_csv(url)\n",
        "\n",
        "# 1\n",
        "XColumns = [\"SCI\", \"REA\"]\n",
        "yColumn = \"MAT\"\n",
        "X = df[XColumns]\n",
        "y = df[yColumn]\n",
        "\n",
        "metodo = LinearRegression()\n",
        "modelo = metodo.fit(X.values,y)\n",
        "\n",
        "p = modelo.predict([[400,450]])[0]\n",
        "\n",
        "p"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ruW7A_B6naO8"
      },
      "source": [
        "Como el RMSE es aproximadamente 11.75, tendremos que con un 95% de probabilidades el valor real está entre"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B3qasyylnaO8"
      },
      "outputs": [],
      "source": [
        "RMSE = 11.75\n",
        "(p-1.96*RMSE,p+1.96*RMSE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "amXcxNArnaO8"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "df[[\"MAT\"]].hist()\n",
        "plt.plot([p-1.96*RMSE,p-1.96*RMSE],[0,1],color=\"pink\",linewidth=5)\n",
        "plt.plot([p+1.96*RMSE,p+1.96*RMSE],[0,1],color=\"pink\",linewidth=5)\n",
        "plt.plot([p,p],[0,1],color=\"yellow\",linewidth=5)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2fp0dNA7naO9"
      },
      "source": [
        "Sin embargo, los siguientes diagramas de residuos nos indican que algo no está funcionando como esperábamos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GETL1IZRnaO9"
      },
      "outputs": [],
      "source": [
        "X = df[XColumns]\n",
        "y = df[yColumn]\n",
        "\n",
        "x = range(len(y))\n",
        "y_pred = modelo.predict(X.values)\n",
        "plt.scatter(x,y_pred,color=\"red\",s=1)\n",
        "plt.scatter(x,y,color=\"blue\",s=8)\n",
        "for i,v in enumerate(y_pred):\n",
        "    plt.plot([x[i],x[i]], [v-2*RMSE,v+2*RMSE],color=\"green\")\n",
        "#for y_v in y_pred:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c1NvVBPUnaO9"
      },
      "outputs": [],
      "source": [
        "x = range(len(y))\n",
        "fig, ax = plt.subplots(figsize=(15, 5))\n",
        "y_pred = modelo.predict(X.values)\n",
        "ci = 1.96*RMSE\n",
        "for i,v in enumerate(y_pred):\n",
        "    plt.plot([x[i],x[i]], [v,y[i]],color=\"green\")\n",
        "ax.fill_between(x, ( y_pred-ci), ( y_pred+ci), color='b', alpha=.1)\n",
        "ax.scatter(x,y_pred,color=\"red\",s=8)\n",
        "ax.scatter(x,y,color=\"blue\",s=8)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QCCbpmAKnaO9"
      },
      "outputs": [],
      "source": [
        "y_pred = metodo.predict(X.values)\n",
        "\n",
        "x_plot = plt.scatter(y_pred, (y_pred - y), c='b')\n",
        "plt.hlines(y=0, xmin= -1, xmax=800)\n",
        "\n",
        "plt.hlines(y=2*RMSE, xmin= -1, xmax=800,color=\"r\")\n",
        "plt.hlines(y=-2*RMSE, xmin= -1, xmax=800,color=\"r\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lxHuhfgpnaO9"
      },
      "source": [
        "<a name=\"mejorando\"></a>\n",
        "## Mejorando el modelo\n",
        "\n",
        "El histograma nos sugiere que quizás el modelo sea mejor si dividimos el conjunto en dos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yfk6kgkonaO9"
      },
      "outputs": [],
      "source": [
        "df2 = df[df[yColumn]<450]\n",
        "X = df2[XColumns]\n",
        "y = df2[yColumn]\n",
        "\n",
        "metodo = LinearRegression()\n",
        "modelo = metodo.fit(X.values,y)\n",
        "\n",
        "r2,RMSE,mae,bias = evalua_regresion(df2,XColumns,yColumn)\n",
        "print(RMSE)\n",
        "\n",
        "x = range(len(y))\n",
        "y_pred = modelo.predict(X.values)\n",
        "plt.scatter(x,y_pred,color=\"red\",s=1)\n",
        "plt.scatter(x,y,color=\"blue\",s=8)\n",
        "for i,v in enumerate(y_pred):\n",
        "    plt.plot([x[i],x[i]], [v-2*RMSE,v+2*RMSE],color=\"green\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YewyFsAznaO-"
      },
      "outputs": [],
      "source": [
        "x_plot = plt.scatter(y_pred, (y_pred - y), c='b')\n",
        "plt.hlines(y=0, xmin= -1, xmax=800)\n",
        "\n",
        "plt.hlines(y=2*RMSE, xmin= -1, xmax=800,color=\"r\")\n",
        "plt.hlines(y=-2*RMSE, xmin= -1, xmax=800,color=\"r\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2oDZVMvFnaO-"
      },
      "outputs": [],
      "source": [
        "df2 = df[df[yColumn]>=450]\n",
        "X = df2[XColumns]\n",
        "y = df2[yColumn]\n",
        "\n",
        "metodo = LinearRegression()\n",
        "modelo = metodo.fit(X.values,y)\n",
        "\n",
        "r2,RMSE,mae,bias = evalua_regresion(df2,XColumns,yColumn)\n",
        "print(RMSE)\n",
        "\n",
        "x = range(len(y))\n",
        "y_pred = modelo.predict(X.values)\n",
        "plt.scatter(x,y_pred,color=\"red\",s=1)\n",
        "plt.scatter(x,y,color=\"blue\",s=8)\n",
        "for i,v in enumerate(y_pred):\n",
        "    plt.plot([x[i],x[i]], [v-2*RMSE,v+2*RMSE],color=\"green\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OgAFtTxpnaO-"
      },
      "outputs": [],
      "source": [
        "x_plot = plt.scatter(y_pred, (y_pred - y), c='b')\n",
        "plt.hlines(y=0, xmin= -1, xmax=800)\n",
        "\n",
        "plt.hlines(y=2*RMSE, xmin= -1, xmax=800,color=\"r\")\n",
        "plt.hlines(y=-2*RMSE, xmin= -1, xmax=800,color=\"r\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wJAXHJljnaO-"
      },
      "source": [
        "<a name=\"lasso\"></a>\n",
        "##  Ridge y Lasso\n",
        "\n",
        "Muy útil cuando hay pocos valores para entrenar"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_wfBb0mNnaO-"
      },
      "outputs": [],
      "source": [
        "# Carga del fichero\n",
        "import pandas as pd\n",
        "url = \"https://raw.githubusercontent.com/RafaelCaballero/tdm/master/datos/pisaDataClean.csv\"\n",
        "df = pd.read_csv(url)\n",
        "\n",
        "# 1\n",
        "XColumns = [\"SCI\", \"REA\"]\n",
        "yColumn = \"MAT\"\n",
        "X = df[XColumns]\n",
        "y = df[yColumn]\n",
        "\n",
        "# 2\n",
        "from sklearn.model_selection import train_test_split\n",
        "test = 0.95\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size= test)\n",
        "\n",
        "# 3\n",
        "from sklearn.linear_model import LinearRegression\n",
        "metodo = LinearRegression()\n",
        "modelo = metodo.fit(X_train,y_train)\n",
        "\n",
        "# 4\n",
        "from sklearn.metrics import r2_score,mean_squared_error,mean_absolute_error\n",
        "import math\n",
        "y_pred = modelo.predict(X_test)\n",
        "r2 = r2_score(y_test,y_pred)\n",
        "rmse = math.sqrt(mean_squared_error(y_test,y_pred))\n",
        "mae = mean_absolute_error(y_test,y_pred)\n",
        "print(f\"r^2: {round(r2,3)} RMSE: {round(rmse,3)}, MAE:{round(mae,3)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "32dgJbkgnaO-"
      },
      "outputs": [],
      "source": [
        "from sklearn.linear_model import Lasso\n",
        "modelo = Lasso(alpha=6).fit(X_train, y_train)\n",
        "y_pred = modelo.predict(X_test)\n",
        "r2 = r2_score(y_test,y_pred)\n",
        "rmse = math.sqrt(mean_squared_error(y_test,y_pred))\n",
        "mae = mean_absolute_error(y_test,y_pred)\n",
        "print(f\"r^2: {round(r2,3)} RMSE: {round(rmse,3)}, MAE:{round(mae,3)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_8u8Kfm5naO-"
      },
      "outputs": [],
      "source": [
        "from sklearn.linear_model import Ridge\n",
        "modelo = Ridge(alpha=6).fit(X_train, y_train)\n",
        "y_pred = modelo.predict(X_test)\n",
        "r2 = r2_score(y_test,y_pred)\n",
        "rmse = math.sqrt(mean_squared_error(y_test,y_pred))\n",
        "mae = mean_absolute_error(y_test,y_pred)\n",
        "print(f\"r^2: {round(r2,3)} RMSE: {round(rmse,3)}, MAE:{round(mae,3)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aIf2V76znaO_"
      },
      "source": [
        "ElasticNet combina los dos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JAZ_BNEvnaO_"
      },
      "outputs": [],
      "source": [
        "from sklearn.linear_model import ElasticNet\n",
        "modelo = ElasticNet(alpha=6, l1_ratio=0.5).fit(X_train, y_train)\n",
        "y_pred = modelo.predict(X_test)\n",
        "r2 = r2_score(y_test,y_pred)\n",
        "rmse = math.sqrt(mean_squared_error(y_test,y_pred))\n",
        "mae = mean_absolute_error(y_test,y_pred)\n",
        "print(f\"r^2: {round(r2,3)} RMSE: {round(rmse,3)}, MAE:{round(mae,3)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<a name=\"series\"></a>\n",
        "##  Series temporales\n",
        "\n",
        "El principal problema es preparar los datos para que coincidan el \"futuro\" que queremos\n"
      ],
      "metadata": {
        "id": "8HwwXrW2QnQX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "url = \"https://raw.githubusercontent.com/RafaelCaballero/BME/main/data/currencies.csv\"\n",
        "df_cur = pd.read_csv(url)[[\"Close_CAD\",\"Close_JPY\",\"Close_EUR\"]]\n",
        "df_cur"
      ],
      "metadata": {
        "id": "_pyfkkpYRUdy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_cur.describe()"
      ],
      "metadata": {
        "id": "Xap8qvkCR-0V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "def estadísticas(df):\n",
        "  # solo las columnas numéricas\n",
        "  df2 = df.select_dtypes(include=[\"number\"])\n",
        "  datos = []\n",
        "  for c in df2:\n",
        "      variable = df2[c]\n",
        "      datos.append([variable.mean(), variable.median(), variable.std(), (variable-variable.median()).abs().median()])\n",
        "\n",
        "  estad = pd.DataFrame(datos,columns=[\"mean\",\"median\",\"std\",\"MAD\"],index=df2.columns)\n",
        "  return estad\n",
        "\n",
        "estadísticas(df_cur)"
      ],
      "metadata": {
        "id": "EP6C3Pr4STRX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Primer intento:"
      ],
      "metadata": {
        "id": "MZbiABk6RqVE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def regresión(df,XColumns,yColumn):\n",
        "  # 1\n",
        "  X = df[XColumns]\n",
        "  y = df[yColumn]\n",
        "\n",
        "  # 2\n",
        "  from sklearn.model_selection import train_test_split\n",
        "  test = 0.70\n",
        "  X_train, X_test, y_train, y_test = train_test_split(X, y, test_size= test)\n",
        "\n",
        "  # 3\n",
        "  from sklearn.linear_model import LinearRegression\n",
        "  metodo = LinearRegression()\n",
        "  modelo = metodo.fit(X_train,y_train)\n",
        "\n",
        "  # 4\n",
        "  from sklearn.metrics import r2_score,mean_squared_error,mean_absolute_error\n",
        "  import math\n",
        "  y_pred = modelo.predict(X_test)\n",
        "  r2 = r2_score(y_test,y_pred)\n",
        "  rmse = math.sqrt(mean_squared_error(y_test,y_pred))\n",
        "  mae = mean_absolute_error(y_test,y_pred)\n",
        "  print(f\"r^2: {round(r2,3)} RMSE: {round(rmse,3)}, MAE:{round(mae,3)}\")\n",
        "\n",
        "\n",
        "XColumns = [\"Close_CAD\", \"Close_JPY\"]\n",
        "yColumn = \"Close_EUR\"\n",
        "regresión(df_cur,XColumns,yColumn)"
      ],
      "metadata": {
        "id": "nh0l85QvRpLs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "x = range(len(y))\n",
        "fig, ax = plt.subplots(figsize=(15, 5))\n",
        "y_pred = modelo.predict(X.values)\n",
        "ci = 1.96*rmse\n",
        "for i,v in enumerate(y_pred):\n",
        "    plt.plot([x[i],x[i]], [v,y[i]],color=\"green\",alpha=0.1)\n",
        "ax.fill_between(x, ( y_pred-ci), ( y_pred+ci), color='b', alpha=.1)\n",
        "ax.scatter(x,y_pred,color=\"red\",s=1, label=\"predicho\",alpha=0.5)\n",
        "ax.scatter(x,y,color=\"blue\",s=1,label=\"real\",alpha=0.5)\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "FchQR7YUSqay"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Sin embargo esto está mal y por varias razones:\n",
        "\n",
        "1 Estamos calculando el cierre del mismo día...intentamos predecir el dato que ya tenemos\n",
        "\n",
        "2 Mezclamos futuros y pasados (solución: TimeSeriesSplit())"
      ],
      "metadata": {
        "id": "l2C4GUnrUdzr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "futuro = 200 #  días\n",
        "euro_f = df_cur.loc[futuro:,\"Close_EUR\"]\n",
        "euro_f, df_cur.Close_EUR\n"
      ],
      "metadata": {
        "id": "TWrFzWL8VI1X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "euro_f2  = euro_f.reset_index(drop=True)\n",
        "euro_f2"
      ],
      "metadata": {
        "id": "9dIJNiErWP2E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_cur[\"label\"] = euro_f2\n",
        "df_cur"
      ],
      "metadata": {
        "id": "20di2xlsWkFG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Tenemos que quitar los nulos; ponemos todo junto"
      ],
      "metadata": {
        "id": "73JxiziGXFU6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "futuro = 2 #  días\n",
        "euro_f = df_cur.loc[futuro:,\"Close_EUR\"]\n",
        "euro_f, df_cur.Close_EUR\n",
        "euro_f2  = euro_f.reset_index(drop=True)\n",
        "df_cur[\"label\"] = euro_f2\n",
        "\n",
        "XColumns = [\"Close_CAD\", \"Close_JPY\"]\n",
        "yColumn = \"label\"\n",
        "regresión(df_cur.dropna(),XColumns,yColumn)"
      ],
      "metadata": {
        "id": "gp-PPVD7XImy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "XColumns = [\"Close_CAD\", \"Close_JPY\", \"Close_EUR\"]\n",
        "yColumn = \"label\"\n",
        "df = df_cur.dropna()\n",
        "regresión(df,XColumns,yColumn)"
      ],
      "metadata": {
        "id": "IrP3OhqtZnig"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Esto tiene muy buena pinta, pero debemos comparar con la predicción más simple: la predicción naïve"
      ],
      "metadata": {
        "id": "Bl0LawUBYusv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = df.Close_EUR\n",
        "y_test = df.label\n",
        "r2 = r2_score(y_test,y_pred)\n",
        "rmse = math.sqrt(mean_squared_error(y_test,y_pred))\n",
        "mae = mean_absolute_error(y_test,y_pred)\n",
        "print(f\"r^2: {round(r2,3)} RMSE: {round(rmse,3)}, MAE:{round(mae,3)}\")"
      ],
      "metadata": {
        "id": "ZOeWEbY9Yt3X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "La predicción no era tan buena como pensábamos..."
      ],
      "metadata": {
        "id": "JojTQg2pahIb"
      }
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}